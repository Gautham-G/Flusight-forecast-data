{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faf0e26b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import glob\n",
    "from epiweeks import Week\n",
    "from metrics import *\n",
    "EPS = 1e-6\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78744bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground truth\n",
    "df_ground_truth = pd.read_csv('ground_truth.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb072fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_week</th>\n",
       "      <th>location</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>202201</td>\n",
       "      <td>AK</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>202202</td>\n",
       "      <td>AK</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>202203</td>\n",
       "      <td>AK</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>202204</td>\n",
       "      <td>AK</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>202205</td>\n",
       "      <td>AK</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     predicted_week location  value\n",
       "335          202201       AK    3.0\n",
       "336          202202       AK   15.0\n",
       "337          202203       AK   12.0\n",
       "338          202204       AK    1.0\n",
       "339          202205       AK    1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ground_truth.head()\n",
    "df_grnd = df_ground_truth[['epiweek', 'region', 'cdc_flu_hosp']]\n",
    "df_grnd = df_grnd[df_grnd['epiweek']>=202201]\n",
    "df_grnd = df_grnd.rename(columns = {'epiweek':\"predicted_week\", \"cdc_flu_hosp\":\"value\", \"region\":\"location\"})\n",
    "df_grnd['location'] = df_grnd['location'].str.replace('X', 'US')\n",
    "df_grnd['location'] = df_grnd['location'].str.replace('TUS', 'TX')\n",
    "df_grnd = df_grnd.sort_values('location', kind = 'mergesort')\n",
    "# df_grnd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6356e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = './predictions.csv' \n",
    "df_total = pd.read_csv(file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "191cc05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total['model'].nunique()\n",
    "df_final = df_total.copy()\n",
    "all_model_names = np.array(df_final['model'].drop_duplicates())\n",
    "# a = []\n",
    "# for i in all_model_names:\n",
    "#     b = df_final[(df_final['model']==i) & (df_final['type']=='point')]\n",
    "#     if(len(np.array(b))==0):\n",
    "#         a.append(i)\n",
    "#         df_final = df_final[df_final['model']!=i]\n",
    "# for model in all_model_names:\n",
    "#     a = df_final[df_final['model']==model]\n",
    "#     if a['forecast_week'].min()>202204:\n",
    "#         df_final = df_final[df_final['model']!=model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e27f57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model_names = np.array(df_final['model'].drop_duplicates())\n",
    "df_gt = df_final[df_final['model']=='GT-FluFNP']\n",
    "\n",
    "# GT-FluFNP model hasn't predicted for some locations \n",
    "all_regions = np.array(df_gt['location'].drop_duplicates())\n",
    "regions_ground_truth = np.array(df_grnd['location'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f471fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_point = df_final[df_final['type']=='point']\n",
    "df_quant = df_final[df_final['type']=='quantile']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cb33a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([202202, 202203, 202204, 202205, 202206, 202207, 202208, 202201,\n",
       "       202209])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weeks = np.array(df_point['forecast_week'].drop_duplicates())\n",
    "max_week = df_grnd['predicted_week'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ffc1614",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/80/kmkjmw951tz6y67zc2c8fyd00000gn/T/ipykernel_1577/2765094017.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_point['predicted_week'] = df_point['forecast_week']+df_point['ahead']\n"
     ]
    }
   ],
   "source": [
    "df_point['predicted_week'] = df_point['forecast_week']+df_point['ahead']\n",
    "\n",
    "# Have ground truth only till week 10  \n",
    "\n",
    "df_point = df_point[df_point['predicted_week']<=max_week] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d79f04f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merging the two datasets on predicted week\n",
    "df_newpoint = pd.merge(df_point, df_grnd, on = \"predicted_week\")\n",
    "# Removing all unnecessary merges\n",
    "df_newpoint = df_newpoint[df_newpoint['location_x'] == df_newpoint['location_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33b3f915",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_all = []\n",
    "model_all= []\n",
    "mape_all = []\n",
    "week_ahead = []\n",
    "regions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38f0dc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gauthamgururajan/Desktop/GT/Flusight/Flusight-forecast-data/metrics.py:19: RuntimeWarning: Mean of empty slice.\n",
      "  return np.sqrt(((predictions - targets) ** 2).mean())\n",
      "/Users/gauthamgururajan/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/gauthamgururajan/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n"
     ]
    }
   ],
   "source": [
    "for model in all_model_names:\n",
    "    for i in range(1, 5):\n",
    "        for region in all_regions:\n",
    "            sample = df_newpoint[   (df_newpoint['model']==model)  &   (df_newpoint['ahead']==i)  & (df_newpoint['location_x']==region) ]['value_x'].values\n",
    "            target = df_newpoint[   (df_newpoint['model']==model)  &   (df_newpoint['ahead']==i)  & (df_newpoint['location_x']==region) ]['value_y'].values\n",
    "            rmse_all.append(rmse(sample, target))\n",
    "\n",
    "#             Deal with inf values\n",
    "            target = np.array([EPS if x ==0 else x for x in target]).reshape((len(target), 1))\n",
    "            mape_all.append(mape(sample, target))\n",
    "            model_all.append(model)\n",
    "            week_ahead.append(i)\n",
    "            regions.append(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5f84fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_point_scores = pd.DataFrame.from_dict({'Model':model_all, 'RMSE':rmse_all, 'MAPE':mape_all, 'Weeks ahead':week_ahead, 'Location':regions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbe8d76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_point_scores.to_csv('point_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "850e255b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target is ground truth\n",
    "df_quant = df_final[df_final['type']=='quantile']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29cf6de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_val = (df_quant['value']-df_quant['value'].min())/(df_quant['value'].max()-df_quant['value'].min())\n",
    "\n",
    "norm_df_quant = df_quant.copy()\n",
    "norm_df_quant['predicted_week']= norm_df_quant['forecast_week']+norm_df_quant['ahead']\n",
    "norm_df_quant = norm_df_quant[norm_df_quant['predicted_week']<=max_week] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e985f6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "week_ahead = []\n",
    "regions = []\n",
    "crps_all = []\n",
    "ls_all = []\n",
    "model_all = []\n",
    "cs_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2aace1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_newpoint = df_newpoint[df_newpoint['model']!='GH-Flusight']\n",
    "# norm_df_quant = norm_df_quant[norm_df_quant['model']!='GH-Flusight']\n",
    "\n",
    "\n",
    "# Problem - some 'ahead' start differently?\n",
    "# Problem - some weeks start from 202205\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "39447b8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model  CEID-Walk\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Model  CMU-TimeSeries\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Model  CU-ensemble\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Model  Flusight-baseline\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Model  Flusight-ensemble\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Model  GH-Flusight\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Model  GT-FluFNP\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Model  GT-FluFNP-raw\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Model  IEM_Health-FluProject\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Model  JHUAPL-Gecko\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Model  LUcompUncertLab-TEVA\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Model  LUcompUncertLab-VAR2\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Model  LUcompUncertLab-VAR2K\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Model  LUcompUncertLab-VAR2K_plusCOVID\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Model  LUcompUncertLab-VAR2_plusCOVID\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Model  LUcompUncertLab-humanjudgment\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Model  LosAlamos_NAU-CModel_Flu\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Model  MOBS-GLEAM_FLUH\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Model  PSI-DICE\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Model  SGroup-RandomForest\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Model  SGroup-SIkJalpha\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Model  SigSci-CREG\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Model  SigSci-TSENS\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Model  UMass-trends_ensemble\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Model  UT_FluCast-Voltaire\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Model  UVAFluX-Ensemble\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n",
      "Model  VTSanghani-ExogModel\n",
      "Week ahead  1\n",
      "Week ahead  2\n",
      "Week ahead  3\n",
      "Week ahead  4\n"
     ]
    }
   ],
   "source": [
    "# All models\n",
    "for model in all_model_names:\n",
    "    print('Model ', model)\n",
    "    \n",
    "#     All Weeks ahead\n",
    "    for i in range(1, 5):\n",
    "        print('Week ahead ', i)\n",
    "        \n",
    "#         All regions\n",
    "        for region in all_regions:\n",
    "            \n",
    "#             Dataset with information about Ground truth ('value_y') and predictions ('value_x') \n",
    "            target = df_newpoint[ (df_newpoint['model']==model) & (df_newpoint['ahead']==i) & (df_newpoint['location_x']==region)]\n",
    "            \n",
    "            norm_model = norm_df_quant[   (norm_df_quant['model']==model)  &   (norm_df_quant['ahead']==i)  & (norm_df_quant['location']==region) ]\n",
    "            mean_ = []\n",
    "            std_ = []\n",
    "            var_ = []\n",
    "            tg_vals = []\n",
    "            pred_vals = []\n",
    "            \n",
    "            weeks = np.array(target['forecast_week'].drop_duplicates())\n",
    "            if(len(weeks)!=0):\n",
    "                for week in weeks:\n",
    "    #                 Append point predictions\n",
    "                    point_val = target[ (target['forecast_week']==week)]['value_x'].values\n",
    "                    mean_.append(point_val)\n",
    "                    if(len(point_val)==0):\n",
    "                        print(i, week, region, model)\n",
    "\n",
    "    #                 Append point pred as predictions\n",
    "                    predval = target[ (target['forecast_week']==week)]['value_y'].values \n",
    "                    pred_vals.append(predval)\n",
    "                \n",
    "    #                     Append ground truth as target\n",
    "                    tgval = target[ (target['forecast_week']==week)]['value_y'].values\n",
    "                    tg_vals.append(tgval)\n",
    "\n",
    "    #                 Find std from quantiles\n",
    "                    b = norm_model[  (norm_model['forecast_week']==week) &  (norm_model['quantile']==0.75)]['value'].values\n",
    "                    a = norm_model[  (norm_model['forecast_week']==week) &  (norm_model['quantile']==0.25)]['value'].values\n",
    "                    std = (b-a)/1.35\n",
    "                    var = std**2\n",
    "                    std_.append(std)\n",
    "                    var_.append(var)\n",
    "\n",
    "                std_ = np.array(std_)\n",
    "                var_ = np.array(var_)\n",
    "#                 print('var - ', var_.shape, '\\n')\n",
    "                \n",
    "                pred_vals = np.array(pred_vals)\n",
    "#                 print('pred - ', pred_vals.shape, pred_vals, '\\n')\n",
    "                \n",
    "                mean_ = np.array(mean_)\n",
    "                tg_vals = np.array(tg_vals)\n",
    "#                 print('tgvals - ', tg_vals.shape, tg_vals, '\\n')\n",
    "\n",
    "\n",
    "                if(len(tg_vals)==0):\n",
    "                    print(i, region, model)\n",
    "    #             Calculate ls and crps\n",
    "                cr = crps(mean_, std_, tg_vals)\n",
    "                auc, cs, _ = get_pr(pred_vals, var_, tg_vals)\n",
    "                ls = log_score(mean_, std_, tg_vals, window = 0.1)\n",
    "                if(ls<-10):\n",
    "                    ls = -10\n",
    "                elif(ls>10):\n",
    "                    ls = 10\n",
    "                crps_all.append(cr)\n",
    "                ls_all.append(ls)\n",
    "#                 print(cs)\n",
    "                cs_all.append(cs)\n",
    "                \n",
    "            else:\n",
    "                crps_all.append(np.nan)\n",
    "                ls_all.append(np.nan)\n",
    "                cs_all.append(np.nan)\n",
    "            week_ahead.append(i)\n",
    "            regions.append(region)\n",
    "            model_all.append(model)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bc03a69c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5508"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4399e46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spread_scores = pd.DataFrame.from_dict({'Model':model_all, 'Weeks ahead':week_ahead, 'Location':regions, 'LS':ls_all, 'CRPS':crps_all,'CS':cs_all})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "81791b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Weeks ahead</th>\n",
       "      <th>Location</th>\n",
       "      <th>LS</th>\n",
       "      <th>CRPS</th>\n",
       "      <th>CS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>GT-FluFNP</td>\n",
       "      <td>1</td>\n",
       "      <td>AK</td>\n",
       "      <td>-6.548632</td>\n",
       "      <td>3.229898</td>\n",
       "      <td>4.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>GT-FluFNP</td>\n",
       "      <td>1</td>\n",
       "      <td>AL</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>7.963596</td>\n",
       "      <td>4.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>GT-FluFNP</td>\n",
       "      <td>1</td>\n",
       "      <td>AR</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>7.797945</td>\n",
       "      <td>4.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>GT-FluFNP</td>\n",
       "      <td>1</td>\n",
       "      <td>AZ</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>18.291955</td>\n",
       "      <td>4.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>GT-FluFNP</td>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>-9.925249</td>\n",
       "      <td>10.067323</td>\n",
       "      <td>4.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1423</th>\n",
       "      <td>GT-FluFNP</td>\n",
       "      <td>4</td>\n",
       "      <td>VT</td>\n",
       "      <td>-2.624291</td>\n",
       "      <td>0.200678</td>\n",
       "      <td>2.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1424</th>\n",
       "      <td>GT-FluFNP</td>\n",
       "      <td>4</td>\n",
       "      <td>WA</td>\n",
       "      <td>-4.804946</td>\n",
       "      <td>6.501649</td>\n",
       "      <td>2.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1425</th>\n",
       "      <td>GT-FluFNP</td>\n",
       "      <td>4</td>\n",
       "      <td>WI</td>\n",
       "      <td>-6.954930</td>\n",
       "      <td>12.581648</td>\n",
       "      <td>2.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1426</th>\n",
       "      <td>GT-FluFNP</td>\n",
       "      <td>4</td>\n",
       "      <td>WV</td>\n",
       "      <td>-5.981085</td>\n",
       "      <td>7.464516</td>\n",
       "      <td>2.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427</th>\n",
       "      <td>GT-FluFNP</td>\n",
       "      <td>4</td>\n",
       "      <td>WY</td>\n",
       "      <td>-4.456487</td>\n",
       "      <td>1.249804</td>\n",
       "      <td>2.736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model  Weeks ahead Location         LS       CRPS     CS\n",
       "1224  GT-FluFNP            1       AK  -6.548632   3.229898  4.104\n",
       "1225  GT-FluFNP            1       AL -10.000000   7.963596  4.104\n",
       "1226  GT-FluFNP            1       AR -10.000000   7.797945  4.104\n",
       "1227  GT-FluFNP            1       AZ -10.000000  18.291955  4.104\n",
       "1228  GT-FluFNP            1       CA  -9.925249  10.067323  4.104\n",
       "...         ...          ...      ...        ...        ...    ...\n",
       "1423  GT-FluFNP            4       VT  -2.624291   0.200678  2.736\n",
       "1424  GT-FluFNP            4       WA  -4.804946   6.501649  2.736\n",
       "1425  GT-FluFNP            4       WI  -6.954930  12.581648  2.736\n",
       "1426  GT-FluFNP            4       WV  -5.981085   7.464516  2.736\n",
       "1427  GT-FluFNP            4       WY  -4.456487   1.249804  2.736\n",
       "\n",
       "[204 rows x 6 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spread_scores.head()\n",
    "df_spread_scores[df_spread_scores['Model']=='GT-FluFNP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "60f41f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spread_scores.to_csv('spread_scores.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
